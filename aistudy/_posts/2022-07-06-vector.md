---
layout: post
title: 벡터란 무엇인가?
description: >
  Math Basics for AI
hide_description: false
category: aistudy
image:
  path: ../../assets/img/thumbnail/vector.png
---

**해당 썸네일은 `Wonkook Lee` 님이 만드신 [`Thumbnail-Maker`](https://wonkooklee.github.io/thumbnail_maker/){:target="_blank"} 를 이용하였습니다**
{:.figcaption}

인공지능을 공부하기 위해 알아야 할 수학 기본 중 내가 몰랐거나 핵심 기본들을 정리하려 한다. 
그 중 첫 번째는 `Vector` 이다.

* this unordered seed list will be replaced by the toc
{:toc}

# What is Vector?

> 벡터는 숫자를 원소로 가지는 리스트(list) 또는 배열(array) 이다.

$$
X = \left[
\begin{matrix}
    x_{1} \\
    x_{2} \\
    x_{3} \\
    . \\
    . \\
    . \\
    x_{d} \\
\end{matrix}
\right]

\quad
\quad
\quad 

X^{T} = \left[
\begin{matrix}
    x_{1}, x_{2}, x_{3},...,x_{d} 
\end{matrix}
\right]
$$

**열벡터와 행벡터**
{:.figcaption}

`d 차원`으로 이루어진 열벡터와 행벡터를 표현해보았다. 벡터는 공간에서 한 점을 나타내는데
원점으로부터 상대적 위치를 표현한다.

# About Norm

이제 벡터의 노름(norm) 을 알아보자. 노름이란 `원점에서부터의 거리` 를 말한다. 또한 크기의 일반화라고 볼 수 있다. 
임의의 차원 d에 대해 성립한다. 수식으로 살펴보자.

$$
L1\, Norm\quad\left\| X \right\|_{1} = \sum_{i=1}^{d}\left| x_{i} \right| 
$$

$$
L2\, Norm\quad\left\| X \right\|_{2} = \sqrt{\sum_{i=1}^{d}\left| x_{i} \right|^2}
$$

**L1 Norm 과 L2 Norm**
{:.figcaption}


L1-노름은 각 성분의 변화량의 절대값을 모두 더하는 것이고 L2-노름은 피타고라스 정리를 이용해 유클리드 거리를 계산하는 것이다.

## Role of Norm in Machine/Deep Learning

기계학습이나 딥러닝에서 Norm 의 역할이 중요하다. 노름은 모델의 error 를 계산할 때 사용된다.
또한 신경망의 prediction과 answer(실제 값 또는 레이블) 사이의 오류를 계산하는데 사용되거나 정규화의 세기를 조절하는 역할을 한다.

예를 들어, 가중치의 `L2-Norm` 을 손실 함수에 더하면 가중치가 커지는 것을 억제할 수 있다. 가중치를 W라 하면 L2 노름에 따른 가중치 감소는 **$$ \frac{1}{2}\lambda W^2 $$** 이 되고, 이 $$ \frac{1}{2}\lambda W^2 $$ 을 손실 함수에 더한다.


여기서 $$ \lambda $$ 는 정규화의 세기를 조절하는 하이퍼 파라미터이다. $$ \lambda $$ 를 크게 설정할수록 큰 가중치에 대한 패널티가 커지게 된다.


# Ending

다시 딥러닝 관련 기본기를 공부하고 있는데 처음에 공부할 때 몰랐던 부분들을 조금이나마 더 이해할 수 있어 좋은 것 같다.
이번 여름방학을 이용해 기초를 다듬어야겠다.